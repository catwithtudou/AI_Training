{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 246,
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    fTrainData = pd.read_csv(\"train.csv\")\n",
    "    fTestData = pd.read_csv(\"test.csv\")\n",
    "    pids = fTestData[\"PassengerId\"].tolist()\n",
    "\n",
    "    def PreProcessData(data):\n",
    "        # 缺失值 中位数补充\n",
    "        data[\"Age\"] = data[\"Age\"].fillna(data[\"Age\"].median())\n",
    "        data[\"Fare\"] = data[\"Fare\"].fillna(data[\"Fare\"].median())\n",
    "\n",
    "        # 文本特征处理\n",
    "        data.loc[data[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "        data.loc[data[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "        data[\"Embarked\"] = data[\"Embarked\"].fillna(\"S\")\n",
    "        data.loc[data[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "        data.loc[data[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "        data.loc[data[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "        def get_title(name):\n",
    "            titleSearch = re.search(\" ([A-Za-z]+)\\\\.\", name)\n",
    "            if titleSearch:\n",
    "                return titleSearch.group(1)\n",
    "            return \"\"\n",
    "\n",
    "        titles = data[\"Name\"].apply(get_title)\n",
    "        title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7, \"Col\": 7, \"Mlle\": 8,\n",
    "                         \"Mme\": 8, \"Don\": 9, \"Dona\": 9, \"Lady\": 10, \"Countess\": 10, \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7,\n",
    "                         \"Ms\": 2}\n",
    "        for k, v in title_mapping.items():\n",
    "            titles[titles == k] = v\n",
    "\n",
    "        # 新特征表示尊称\n",
    "        data[\"Title\"] = [int(i) for i in titles.values.tolist()]\n",
    "        # 新特征表示名字长度\n",
    "        data[\"NameLength\"] = data[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "        # # 相关性分析\n",
    "        # # 相关性协方差表, corr()函数,返回结果接近0说明无相关性,大于0说明是正相关,小于0是负相关.\n",
    "        # train_corr = data.corr()\n",
    "        # print(train_corr)\n",
    "        # # # 画出相关性热力图\n",
    "        # a = plt.subplots(figsize=(15, 9))  #调整画布大小\n",
    "        # a = sns.heatmap(train_corr, vmin=-1, vmax=1, annot=True, square=True)  #画热力图\n",
    "        # plt.show()\n",
    "\n",
    "        # 相关性太差的删除\n",
    "        data.drop(['PassengerId'], axis=1, inplace=True)\n",
    "        data.drop(['Cabin'], axis=1, inplace=True)\n",
    "        # data.drop(['SibSp'], axis=1, inplace=True)\n",
    "        # data.drop(['Parch'], axis=1, inplace=True)\n",
    "        data.drop(['Ticket'], axis=1, inplace=True)\n",
    "        data.drop(['Name'], axis=1, inplace=True)\n",
    "\n",
    "        return data\n",
    "\n",
    "    PreProcessData(fTrainData)\n",
    "    PreProcessData(fTestData)\n",
    "\n",
    "    trainData = fTrainData.iloc[:, 1:]\n",
    "    trainLabel = fTrainData.iloc[:, 0]\n",
    "    testData = fTestData.iloc[:, :]\n",
    "\n",
    "    return trainData, trainLabel,testData, pids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据预处理"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "trainData,trainLabel,testData,pids = loadData()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征工程"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "def FeatureEngineering(data, COMPONENT_NUM=0.8):\n",
    "    # 标准化\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    s_data = scaler.fit_transform(data)\n",
    "\n",
    "    # 降维\n",
    "    # 不降维时准确率上升\n",
    "    # pca = PCA(n_components=COMPONENT_NUM, whiten=False)\n",
    "    # pca.fit(s_data)\n",
    "    # pca_data = pca.transform(s_data)\n",
    "    # print(\"方差大小:\\n\", pca.explained_variance_, \"方差占比:\\n\", pca.explained_variance_ratio_)\n",
    "    # print(\"特征数量: %s\" % pca.n_components_)\n",
    "    # print(\"总方差占比: %s\" % sum(pca.explained_variance_ratio_))\n",
    "\n",
    "    return s_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "pcaTrainData = FeatureEngineering(trainData)\n",
    "pcaTestData = FeatureEngineering(testData)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练&模型融合"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "def TrainModelByLR(trainData, trainLabel):\n",
    "    model = LogisticRegression(random_state=1)\n",
    "    scores = cross_val_score(model, trainData, trainLabel, cv=5, scoring=\"roc_auc\")\n",
    "    print(scores.mean(), \"\\n\", scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8592520159240402 \n",
      " [0.86126482 0.84131016 0.86831551 0.84157754 0.88379205]\n"
     ]
    }
   ],
   "source": [
    "TrainModelByLR(pcaTrainData, trainLabel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}